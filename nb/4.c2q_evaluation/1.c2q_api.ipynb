{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import tqdm\n",
    "\n",
    "sys.path.insert(0, '../../')\n",
    "import map_modifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_c2q_mapping(string):\n",
    "    post_data = {\n",
    "        'inc': string,\n",
    "        'exc': '',\n",
    "        'initialevent': '',\n",
    "        'rule': True,\n",
    "        'ml': True,\n",
    "        'abb': True,\n",
    "        'obstart': '',\n",
    "        'obend': '',\n",
    "        'daysbefore': '0',\n",
    "        'daysafter': '0',\n",
    "        'limitto': 'All'\n",
    "    }\n",
    "    base = 'http://www.ohdsi.org/web/criteria2query/'\n",
    "    with requests.Session() as s:\n",
    "        # Clear cookies\n",
    "        s.cookies.clear()\n",
    "        \n",
    "        # Post the data first\n",
    "        post_response = s.post(\n",
    "            base + 'main/autoparse',\n",
    "            data=post_data,\n",
    "            timeout=10,\n",
    "        )\n",
    "\n",
    "        get_response = s.get(\n",
    "            base + 'queryformulate/formulateCohort',\n",
    "            data={},\n",
    "            timeout=10,\n",
    "        )\n",
    "    \n",
    "    if get_response.status_code in {500, 504}:\n",
    "        return post_response, get_response\n",
    "\n",
    "    responses_list = (\n",
    "        json.loads(get_response.json()['jsonResult'])\n",
    "        ['ConceptSets']\n",
    "    )\n",
    "    return responses_list\n",
    "\n",
    "\n",
    "def format_results(results, criteria_dict):\n",
    "    \"\"\"Format results depending on whether successful or erroneous\"\"\"\n",
    "    if isinstance(results, tuple):\n",
    "        return [], _format_error(results, criteria_dict)\n",
    "    return _format_correct(results, criteria_dict), []\n",
    "\n",
    "\n",
    "def _format_error(results, criteria_dict):\n",
    "    criteria_dict.update({\n",
    "        'post_request': results[0],\n",
    "        'get_request': results[1],\n",
    "    })\n",
    "    return [criteria_dict,]\n",
    "\n",
    "\n",
    "def _format_correct(results, criteria_dict):\n",
    "    outputs = list()\n",
    "    for res in results:\n",
    "        if not res.get('name'):\n",
    "            continue\n",
    "        result_dict = {\n",
    "            **criteria_dict.copy(),\n",
    "            'cohort_name': res['name'],\n",
    "        }\n",
    "        for item in res['expression']['items']:\n",
    "            outputs.append({\n",
    "                **result_dict,\n",
    "                'concept': item['concept'],\n",
    "            })\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420 \n",
      " {'NCT_id': 'NCT03937804', 'matched_string': 'scoliosis', 'criteria_string': 'bronchitis lung transplant kyphoscoliosis sarcoidosis bronchopulmonary dysplasia', 'source': 'uog'}\n"
     ]
    }
   ],
   "source": [
    "uog_df = pd.read_csv('../../data/annotations/annotate_notes_uog.csv')\n",
    "\n",
    "uog_criteria_strings = (\n",
    "    uog_df\n",
    "    .filter(items=['NCT_id', 'matched_string', 'criteria_string'])\n",
    "    .dropna()\n",
    "    .drop_duplicates()\n",
    "    .assign(\n",
    "        criteria_string=lambda df: df['criteria_string'].apply(map_modifiers.utils.normalize_text),\n",
    "        matched_string=lambda df: df['matched_string'].apply(map_modifiers.utils.normalize_text),\n",
    "    )\n",
    "    .assign(\n",
    "        criteria_string=lambda df: df.apply(\n",
    "            lambda row: map_modifiers.recognize_parents.get_word_margin(row['criteria_string'],\n",
    "                                                                        row['matched_string'], 3)[0],\n",
    "            axis=1),\n",
    "        source='uog'\n",
    "    )\n",
    "    .to_dict('records')\n",
    ")\n",
    "\n",
    "print(len(uog_criteria_strings), '\\n', uog_criteria_strings[0])\n",
    "\n",
    "for criteria_dict in uog_criteria_strings:\n",
    "    assert criteria_dict['criteria_string'].index(criteria_dict['matched_string'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420 \n",
      " {'NCT_id': 'NCT00000456', 'matched_string': 'panic', 'criteria_string': 'of major depression panic disorder obsessive-compulsive disorder', 'source': 'hrn'}\n"
     ]
    }
   ],
   "source": [
    "hrn_df = pd.read_csv('../../data/annotations/annotate_notes_hr2479.csv')\n",
    "\n",
    "hrn_criteria_strings = (\n",
    "    hrn_df\n",
    "    .filter(items=['NCT_id', 'matched_string', 'criteria_string'])\n",
    "    .dropna()\n",
    "    .drop_duplicates()\n",
    "    .assign(\n",
    "        criteria_string=lambda df: df['criteria_string'].apply(map_modifiers.utils.normalize_text),\n",
    "        matched_string=lambda df: df['matched_string'].apply(map_modifiers.utils.normalize_text),\n",
    "    )\n",
    "    .assign(\n",
    "        criteria_string=lambda df: df.apply(\n",
    "            lambda row: map_modifiers.recognize_parents.get_word_margin(\n",
    "                row['criteria_string'], row['matched_string'], 3)[0] \n",
    "            if row['matched_string'] in row['criteria_string'] else row['criteria_string'],\n",
    "            axis=1),\n",
    "        source='hrn'\n",
    "    )\n",
    "    .to_dict('records')\n",
    ")\n",
    "\n",
    "print(len(hrn_criteria_strings), '\\n', hrn_criteria_strings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine criteria strings from Harry and Undina\n",
    "all_criteria_string = [*uog_criteria_strings, *hrn_criteria_strings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "150d46fd87074307ab633a4010c334b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=840), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct_results = list()\n",
    "error_results = list()\n",
    "for criteria_dict in tqdm.tqdm_notebook(all_criteria_string):\n",
    "    results = get_c2q_mapping(criteria_dict['criteria_string'])\n",
    "    \n",
    "    correct, error = format_results(results, criteria_dict)\n",
    "    \n",
    "    correct_results.extend(correct)\n",
    "    error_results.extend(error)\n",
    "    time.sleep(1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Response' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3df8f9dc555d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#  Errors include no mappings, rate throttling, etc.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0merror_result\u001b[0m \u001b[0;32min\u001b[0m \u001b[0merror_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0merror_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'post_request'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'post_request'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0merror_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'get_request'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'get_request'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Response' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "# Dump correct results to JSON file\n",
    "with open('../../data/c2q/c2q_mappings_correct.json', 'w') as f:\n",
    "    json.dump(correct_results, f, indent=2)\n",
    "\n",
    "# Dump errors to a separate JSON file\n",
    "#  Errors include no mappings, rate throttling, etc.\n",
    "for error_result in error_results:\n",
    "    error_result['post_request'] = error_result['post_request'].decode('utf-8')\n",
    "    error_result['get_request'] = error_result['get_request'].decode('utf-8')\n",
    "\n",
    "with open('../../data/c2q/c2q_mappings_error.json', 'w') as f:\n",
    "    json.dump(error_results, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save correct results to a .csv also, for easier evaluation later\n",
    "correct_results_df = (\n",
    "    pd.DataFrame(correct_results)\n",
    "    .assign(\n",
    "        concept_code=lambda df: df['concept'].apply(lambda x: x['CONCEPT_CODE']),\n",
    "        concept_name=lambda df: df['concept'].apply(lambda x: x['CONCEPT_NAME']),\n",
    "        vocabulary=lambda df: df['concept'].apply(lambda x: x['VOCABULARY_ID']),\n",
    "        concept_class=lambda df: df['concept'].apply(lambda x: x['CONCEPT_CLASS_ID']),\n",
    "    )\n",
    "    .loc[lambda df: df['vocabulary'] == 'SNOMED', ['NCT_id', 'matched_string', 'criteria_string',\n",
    "                                                   'source', 'cohort_name', 'concept_code',\n",
    "                                                   'concept_name']]\n",
    ")\n",
    "\n",
    "correct_results_df.to_csv('../../data/c2q/results_table.csv', index=False)\n",
    "\n",
    "correct_results_df.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:modifiers] *",
   "language": "python",
   "name": "conda-env-modifiers-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
